{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\programdata\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.9.5)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.25.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 1: Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">Main Page</h1>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>,\n",
       " <h2>Navigation menu</h2>,\n",
       " <h3 id=\"p-personal-label\">\n",
       " <span>Personal tools</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-namespaces-label\">\n",
       " <span>Namespaces</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-variants-label\">\n",
       " <span>Variants</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-views-label\">\n",
       " <span>Views</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-cactions-label\">\n",
       " <span>More</span>\n",
       " </h3>,\n",
       " <h3>\n",
       " <label for=\"searchInput\">Search</label>\n",
       " </h3>,\n",
       " <h3 id=\"p-navigation-label\">\n",
       " <span>Navigation</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-interaction-label\">\n",
       " <span>Contribute</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-tb-label\">\n",
       " <span>Tools</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-coll-print_export-label\">\n",
       " <span>Print/export</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-wikibase-otherprojects-label\">\n",
       " <span>In other projects</span>\n",
       " </h3>,\n",
       " <h3 id=\"p-lang-label\">\n",
       " <span>Languages</span>\n",
       " </h3>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def header_tag(url):\n",
    "    a=requests.get(url)\n",
    "    b=a.content\n",
    "    soup=BeautifulSoup(b,'html.parser')\n",
    "    return soup.find_all(['h1','h2','h3','h4','h5'])\n",
    "\n",
    "header_tag(\"https://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of\n",
    "release) and save it in form of a CSV file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Movie Name  IMDB Rating Release Year\n",
      "0   The Shawshank Redemption          9.2       (1994)\n",
      "1              The Godfather          9.1       (1972)\n",
      "2     The Godfather: Part II          9.0       (1974)\n",
      "3            The Dark Knight          9.0       (2008)\n",
      "4               12 Angry Men          8.9       (1957)\n",
      "..                       ...          ...          ...\n",
      "95              Citizen Kane          8.3       (1941)\n",
      "96                    Dangal          8.3       (2016)\n",
      "97         Full Metal Jacket          8.2       (1987)\n",
      "98       Ladri di biciclette          8.2       (1948)\n",
      "99       Singin' in the Rain          8.2       (1952)\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def top100_movie_IMDB(url):\n",
    "    a=requests.get(url)\n",
    "    soup=BeautifulSoup(a.content,'html.parser')\n",
    "    \n",
    "    # Lets make some blank lists\n",
    "    name=[]\n",
    "    ratings=[]\n",
    "    year=[]\n",
    "    \n",
    "    for i in soup.find_all('img'):\n",
    "        name.append(i.attrs['alt'])\n",
    "    for i in soup.find_all('strong'):\n",
    "        ratings.append((float(i.text)))\n",
    "    for i in list(soup.find_all('span',attrs={'secondaryInfo'})):\n",
    "        year.append(i.text)\n",
    "        \n",
    "    df1=pd.DataFrame({'Movie Name':name[0:100],\n",
    "                     'IMDB Rating':ratings[0:100],\n",
    "                     'Release Year':year[0:100]})    \n",
    "    print(df1)\n",
    "\n",
    "top100_movie_IMDB('https://www.imdb.com/chart/top')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:3 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year\n",
    "of release) and save it in form of a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Movie Name  IMDB Rating Release Year\n",
      "0   Pather Panchali          8.5       (1955)\n",
      "1          Ratsasan          8.5       (2018)\n",
      "2          Gol Maal          8.5       (1979)\n",
      "3           Nayakan          8.5       (1987)\n",
      "4        Anbe Sivam          8.5       (2003)\n",
      "..              ...          ...          ...\n",
      "95       Bommarillu          8.0       (2006)\n",
      "96            Lucia          8.0       (2013)\n",
      "97          Maqbool          8.0       (2003)\n",
      "98           Bombay          8.0       (1995)\n",
      "99           Omkara          8.0       (2006)\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def top100_Indian_movie_IMDB(url):\n",
    "    a=requests.get(url)\n",
    "    soup=BeautifulSoup(a.content,'html.parser')\n",
    "    \n",
    "    # Lets make some blank lists\n",
    "    name=[]\n",
    "    ratings=[]\n",
    "    year=[]\n",
    "    \n",
    "    for i in soup.find_all('img'):\n",
    "        name.append(i.attrs['alt'])\n",
    "    for i in soup.find_all('strong'):\n",
    "        ratings.append((float(i.text)))\n",
    "    for i in list(soup.find_all('span',attrs={'secondaryInfo'})):\n",
    "        year.append(i.text)\n",
    "        \n",
    "    df1=pd.DataFrame({'Movie Name':name[0:100],\n",
    "                     'IMDB Rating':ratings[0:100],\n",
    "                     'Release Year':year[0:100]})    \n",
    "    print(df1)\n",
    "    \n",
    "top100_Indian_movie_IMDB('https://www.imdb.com/india/top-rated-indian-movies/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7: Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The\n",
    "scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8: Write a python program to extract information about the local weather from the National Weather Service\n",
    "website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day\n",
    "extended forecast display for the city. The data should include period, short description, temperature and\n",
    "description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Period       Short_description  Temperature  \\\n",
      "0  NOW until7:00pm Sat      High Surf Advisory                \n",
      "1                Today                   Sunny  High: 67 °F   \n",
      "2              Tonight            Mostly Clear   Low: 51 °F   \n",
      "3               Sunday                   Sunny  High: 68 °F   \n",
      "4          SundayNight            Mostly Clear   Low: 51 °F   \n",
      "5          M.L.KingDay                   Sunny  High: 67 °F   \n",
      "6          MondayNight  Mostly Clearand Breezy   Low: 52 °F   \n",
      "7              Tuesday         Sunny andBreezy  High: 66 °F   \n",
      "8         TuesdayNight            Mostly Clear   Low: 47 °F   \n",
      "\n",
      "                                         Description  \n",
      "0  Sunny, with a high near 67. Calm wind becoming...  \n",
      "1    Mostly clear, with a low around 51. Calm wind.   \n",
      "2  Sunny, with a high near 68. Calm wind becoming...  \n",
      "3  Mostly clear, with a low around 51. West wind ...  \n",
      "4  Sunny, with a high near 67. North wind around ...  \n",
      "5       Mostly clear, with a low around 52. Breezy.   \n",
      "6               Sunny, with a high near 66. Breezy.   \n",
      "7                Mostly clear, with a low around 47.  \n",
      "8                        Sunny, with a high near 64.  \n"
     ]
    }
   ],
   "source": [
    "# Function Definition\n",
    "def weather(url):\n",
    "    a=requests.get(url)\n",
    "    soup=BeautifulSoup(a.content,'html.parser')\n",
    "    period=[]\n",
    "    short_desc=[]\n",
    "    temp=[]\n",
    "    desc=[]\n",
    "    for i in soup.find_all('p',attrs={'period-name'}):\n",
    "        period.append(i.text)\n",
    "    for i in soup.find_all('p',attrs={'short-desc'}):\n",
    "        short_desc.append(i.text)\n",
    "    for i in soup.find_all('p',attrs={'short-desc'}):\n",
    "        if i.next_sibling is not None:\n",
    "            temp.append(i.next_sibling.text)\n",
    "        else:\n",
    "            temp.append(' ')\n",
    "    for i in soup.find_all('div',attrs={\"col-sm-10 forecast-text\"}):\n",
    "        desc.append(i.text)\n",
    "    df=pd.DataFrame({\"Period\":period,\n",
    "                     \"Short_description\":short_desc,\n",
    "                     \"Temperature\":temp,\n",
    "                     \"Description\":desc[0:9]})\n",
    "    df.to_csv('Extended_forecast.csv')\n",
    "    print(df)\n",
    "\n",
    "# Calling Function\n",
    "weather(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.X6Pyxe3hWMo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9: Write a python program to scrape ‘software developer’ job listings from ‘Monster.com’. It should include all\n",
    "the jobs listed for the next 5 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Job_Names  \\\n",
      "0              Software Developer - .Net   \n",
      "1                 Software Engineer (C#)   \n",
      "2                          Web developer   \n",
      "3                      Android Developer   \n",
      "4                          iOS developer   \n",
      "..                                   ...   \n",
      "120                    computer operator   \n",
      "121  Senior Software Engineer - Java/AWS   \n",
      "122                    ASP.NET Developer   \n",
      "123                Technology Specialist   \n",
      "124                   Big Data Developer   \n",
      "\n",
      "                                               Company  \\\n",
      "0                                       in MNC Company   \n",
      "1                    Kameda Infologics Private Limited   \n",
      "2                   Infomedia Solutions And Consultant   \n",
      "3        iQuest Management Consultants Private Limited   \n",
      "4     Sanda Office Management Services Private Limited   \n",
      "..                                                 ...   \n",
      "120    Muskaan Parveen (Proprietor Of Muskan Industry)   \n",
      "121                                   PlaceElements HR   \n",
      "122               IT-Scient Consulting Private Limited   \n",
      "123                        C P Careers Private Limited   \n",
      "124                        C P Careers Private Limited   \n",
      "\n",
      "                                              location  \n",
      "0                                                Delhi  \n",
      "1                                    Delhi, Thiruva...  \n",
      "2                                                 Pune  \n",
      "3                                                 Pune  \n",
      "4                                    Mumbai, Mumbai...  \n",
      "..                                                 ...  \n",
      "120                                  Cochin / Kochi...  \n",
      "121                                             Mumbai  \n",
      "122                                  Hyderabad / Se...  \n",
      "123                                  Bengaluru / Ba...  \n",
      "124                                  Bengaluru / Ba...  \n",
      "\n",
      "[125 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def soft_dev(url):\n",
    "    driver=webdriver.Chrome(r'C:\\Users\\chromedriver')\n",
    "    driver.get(url)\n",
    "    start_page=0\n",
    "    end_page=4\n",
    "    urls=[]\n",
    "    job_names=[]\n",
    "    company=[]\n",
    "    location=[]\n",
    "    for page in range(start_page,end_page+1):\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        jobs=soup.find_all('div', attrs ={'class':'job-tittle'})\n",
    "        for job in jobs:\n",
    "            l=job.text.split('\\n')\n",
    "            job_names.append(l[0].split('  ')[0])\n",
    "            company.append(l[0].split('  ')[1])\n",
    "            location.append(l[1])\n",
    "                \n",
    "        nxt_button=driver.find_element_by_xpath(\"//button[@class='btn-next-prev btn-next']\")\n",
    "        if nxt_button.text=='Next':\n",
    "            nxt_button.click()\n",
    "            \n",
    "    job_df=pd.DataFrame({'Job_Names':job_names,\n",
    "                         'Company':company,\n",
    "                         'location':location\n",
    "                         })\n",
    "    print(job_df)\n",
    "\n",
    "\n",
    "soft_dev(\"https://www.monsterindia.com/srp/results?query=software%20developer&searchId=1eef9a54-8213-4bcf-9ef7-8605ec8202c5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10:Write a python program to scrape ‘data scientist’ job listings for location ‘New Delhi’ from ‘Monster.com’. It\n",
    "should include all the jobs listed for the next 5 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\chromedriver')\n",
    "driver.get('https://www.monsterindia.com/')\n",
    "\n",
    "search_designation=driver.find_element_by_xpath('//input[@class=\"input search-bar home_ac\"]')\n",
    "search_designation.send_keys('Data Scientist')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_location=driver.find_element_by_xpath('//input[@placeholder=\"Location\"]')\n",
    "search_location.send_keys('New Delhi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath('//input[@class=\"btn\"]')\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets Create Empty lists\n",
    "job_titles=[]\n",
    "company_names=[]\n",
    "locations_list=[]\n",
    "experiences_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=5\n",
    "for i in range(start,end):\n",
    "    title=driver.find_elements_by_xpath('//h3[@class=\"medium\"]')\n",
    "    for i in title:\n",
    "        if i.text is None:\n",
    "            job_titles.append(\"--\") \n",
    "        else:\n",
    "            job_titles.append(i.text)\n",
    "    \n",
    "    company=driver.find_elements_by_xpath('//span[@class=\"company-name\"]')\n",
    "    for i in company:\n",
    "        if i.text is None:\n",
    "            company_names.append(\"--\")\n",
    "        else:\n",
    "            company_names.append(i.text)\n",
    "        \n",
    "    location=driver.find_elements_by_xpath('//div[@class=\"col-xxs-12 col-sm-5 text-ellipsis\"]')\n",
    "    for i in location:\n",
    "        if i.text is None:\n",
    "            locations_list.append('--')\n",
    "        else:\n",
    "            locations_list.append(i.text)\n",
    "        \n",
    "    exp=driver.find_elements_by_xpath('//div[@class=\"exp col-xxs-12 col-sm-3 text-ellipsis\"]')\n",
    "    for i in exp:\n",
    "        if i.text is None:\n",
    "            experiences_list.append('--')\n",
    "        else:\n",
    "            experiences_list.append(i.text)\n",
    "              \n",
    "next_btn=driver.find_element_by_xpath('//button[@class=\"btn-next-prev btn-next\"]')\n",
    "next_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 130 130 130\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(company_names),len(locations_list),len(experiences_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Promax Legal Solution Private Limited</td>\n",
       "      <td>Delhi, Mohali</td>\n",
       "      <td>8-15 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Structured Learning Assistance Consultants Ind...</td>\n",
       "      <td>Delhi, Gurgaon / Gurugram</td>\n",
       "      <td>0-5 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Structured Learning Assistance Consultants Ind...</td>\n",
       "      <td>Delhi, Noida</td>\n",
       "      <td>0-5 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Structured Learning Assistance Consultants Ind...</td>\n",
       "      <td>Delhi, Noida</td>\n",
       "      <td>0-5 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Structured Learning Assistance Consultants Ind...</td>\n",
       "      <td>Delhi, Noida</td>\n",
       "      <td>1-7 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Solitaire Infotech Solution</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1-3 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Hiren B Patel (Proprietor Of Bajaj India Service)</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>0-2 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Shakun Sharma (Proprietor Of FM Industry)</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>0-1 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Rudraksha Fire Security Services</td>\n",
       "      <td>Delhi, Faridabad</td>\n",
       "      <td>0-2 Years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Aaryan Technology</td>\n",
       "      <td>Ahmedabad, Delhi</td>\n",
       "      <td>0-5 Years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Company  \\\n",
       "0                Promax Legal Solution Private Limited   \n",
       "1    Structured Learning Assistance Consultants Ind...   \n",
       "2    Structured Learning Assistance Consultants Ind...   \n",
       "3    Structured Learning Assistance Consultants Ind...   \n",
       "4    Structured Learning Assistance Consultants Ind...   \n",
       "..                                                 ...   \n",
       "125                        Solitaire Infotech Solution   \n",
       "126  Hiren B Patel (Proprietor Of Bajaj India Service)   \n",
       "127          Shakun Sharma (Proprietor Of FM Industry)   \n",
       "128                   Rudraksha Fire Security Services   \n",
       "129                                  Aaryan Technology   \n",
       "\n",
       "                      Location Experience Required  \n",
       "0                Delhi, Mohali          8-15 Years  \n",
       "1    Delhi, Gurgaon / Gurugram           0-5 Years  \n",
       "2                 Delhi, Noida           0-5 Years  \n",
       "3                 Delhi, Noida           0-5 Years  \n",
       "4                 Delhi, Noida           1-7 Years  \n",
       "..                         ...                 ...  \n",
       "125                      Delhi           1-3 Years  \n",
       "126                      Delhi           0-2 Years  \n",
       "127                      Delhi           0-1 Years  \n",
       "128           Delhi, Faridabad           0-2 Years  \n",
       "129           Ahmedabad, Delhi           0-5 Years  \n",
       "\n",
       "[130 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs=pd.DataFrame({'Company':company_names,\n",
    "                  'Location':locations_list,\n",
    "                  'Experience Required':experiences_list})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "‘www.bookpage.com’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summerwater</td>\n",
       "      <td>Sarah Moss</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "      <td>Gabriel García Márquez once wrote, “Everyone h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Winterkeep</td>\n",
       "      <td>Kristin Cashore</td>\n",
       "      <td>YA / YA Fiction</td>\n",
       "      <td>Fans of Kristin Cashore’s previous books set i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amari and the Night Brothers</td>\n",
       "      <td>B. B. Alston</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td>Things are not going well for Amari Peters. He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Crooked Path to Abolition</td>\n",
       "      <td>James Oakes</td>\n",
       "      <td>Nonfiction / History / American History</td>\n",
       "      <td>Abraham Lincoln was not an abolitionist. Inste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Children's Train</td>\n",
       "      <td>Viola Ardone, Clarissa Botsford</td>\n",
       "      <td>Fiction / Historical Fiction</td>\n",
       "      <td>The displacement of children is a vexing probl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Book Name                           Author  \\\n",
       "0                    Summerwater                       Sarah Moss   \n",
       "1                     Winterkeep                  Kristin Cashore   \n",
       "2   Amari and the Night Brothers                     B. B. Alston   \n",
       "3  The Crooked Path to Abolition                      James Oakes   \n",
       "4           The Children's Train  Viola Ardone, Clarissa Botsford   \n",
       "\n",
       "                                     Genre  \\\n",
       "0               Fiction / Literary Fiction   \n",
       "1                          YA / YA Fiction   \n",
       "2                Children's / Middle Grade   \n",
       "3  Nonfiction / History / American History   \n",
       "4             Fiction / Historical Fiction   \n",
       "\n",
       "                                              Review  \n",
       "0  Gabriel García Márquez once wrote, “Everyone h...  \n",
       "1  Fans of Kristin Cashore’s previous books set i...  \n",
       "2  Things are not going well for Amari Peters. He...  \n",
       "3  Abraham Lincoln was not an abolitionist. Inste...  \n",
       "4  The displacement of children is a vexing probl...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bookpage():\n",
    "    response = requests.get('https://bookpage.com/reviews/')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    url_tags = soup.find_all('div', attrs = {'class': 'row-fluid article-row'})\n",
    "    urls = [i.find('h4').find_all('a')[0]['href'] for i in url_tags[0:5]]\n",
    "    book_dict = {}\n",
    "    book_dict[\"Book Name\"] = []\n",
    "    book_dict[\"Author\"] = []\n",
    "    book_dict[\"Genre\"] = []\n",
    "    book_dict[\"Review\"] = []\n",
    "    for url in urls:\n",
    "        book = requests.get('https://www.bookpage.com'+url)\n",
    "        soup = BeautifulSoup(book.content, 'html.parser')\n",
    "        book_dict[\"Book Name\"].append(soup.find('h1').text.replace('\\n',''))\n",
    "        book_dict[\"Author\"].append(soup.find('h4').text.replace('\\n',''))\n",
    "        book_dict[\"Genre\"].append(soup.find('p', attrs = {'class':'genre-links'}).text.replace('\\n',''))\n",
    "        book_dict[\"Review\"].append(soup.find('div', attrs = {'class':'article-body'}).text.replace('\\n',''))\n",
    "    book_df = pd.DataFrame.from_dict(book_dict)\n",
    "    book_df.to_csv('Book Reviews.csv', index = False)\n",
    "    return book_df\n",
    "\n",
    "# Calling Function\n",
    "bookpage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5: Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. \n",
    "You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
